name: Reusable CI

on:
  workflow_call:
    inputs:
      runner:
        description: 'The self-hosted runner to use (e.g., nvidia-h100)'
        required: true
        type: string
      gpu_type:
        description: 'The type of GPU (nvidia or intel)'
        required: true
        type: string
      conda_env_name:
        description: 'The exact name of the pre-existing Conda environment to activate on the runner.'
        required: true
        type: string
      pytorch_version:
        description: 'The PyTorch version to install (e.g., 2.7.0, nightly)'
        required: true
        type: string

jobs:
  test-ops:
    runs-on: ${{ inputs.runner }}
    env:
      FLA_CI_ENV: 1
      PYTORCH_CUDA_VERSION: 'cu128'

    steps:
      # =================================================================
      # STAGE 1: SETUP (Runs only once for the entire job)
      # =================================================================
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Discover Conda Path by Searching Home Directory
        id: find_conda
        shell: bash
        run: |
          set -e
          echo "Searching for Conda installation in home directory ($HOME)..."
          POSSIBLE_NAMES=("miniforge3" "miniconda3" "anaconda3")
          FOUND_PATH=""

          for name in "${POSSIBLE_NAMES[@]}"; do
            CANDIDATE_PATH="$HOME/$name"
            echo "--> Checking for path: ${CANDIDATE_PATH}"
            if [ -d "${CANDIDATE_PATH}" ] && [ -x "${CANDIDATE_PATH}/bin/conda" ]; then
              echo "    Found valid Conda installation: ${CANDIDATE_PATH}"
              FOUND_PATH="${CANDIDATE_PATH}"
              break
            fi
          done

          if [ -n "${FOUND_PATH}" ]; then
            echo "Setting CONDA environment variable to: ${FOUND_PATH}"
            echo "CONDA=${FOUND_PATH}" >> $GITHUB_ENV
          else
            echo "::error::Could not automatically find a Conda installation."
            exit 1
          fi

      - name: Set up Conda from Discovered Path
        uses: conda-incubator/setup-miniconda@v3
        with:
          activate-environment: ""
          auto-update-conda: false
          auto-activate-base: false

      - name: Verify Environment and GPU
        run: |
          conda activate ${{ inputs.conda_env_name }}
          echo "Successfully activated Conda environment: $CONDA_DEFAULT_ENV"
          echo "Python executable path: $(which python)"
          echo "PyTorch version: $(python -c 'import torch; print(torch.__version__)')"
          if python -c "import fla; print('FLA imported successfully')"; then
            echo "FLA is available. Running GPU check."
            python scripts/check_gpu.py
            if [ $? -ne 0 ]; then
              echo "::error::GPU is occupied. Stopping the workflow."
              exit 1
            fi
          else
            # If FLA cannot be imported, we output a warning and continue.
            # This handles cases where the package might not be installed yet.
            echo "::warning::FLA not found or import failed. Skipping dependent GPU check."
          fi

      - name: Check skip keyword in LATEST commit (Push only)
        id: check_skip
        run: |
          if [ "${{ github.event_name }}" = "push" ] && ! [[ "${{ github.ref }}" =~ ^refs/tags/ ]]; then
            COMMIT_MSG=$(jq -r '.head_commit.message' <<< '${{ toJSON(github.event) }}')
            echo "Latest commit message: $COMMIT_MSG"
            if echo "$COMMIT_MSG" | grep -qF "[skip test]"; then
              echo "::notice::Tests skipped by commit message"
              echo "skip_tests=true" >> $GITHUB_OUTPUT
            else
              echo "skip_tests=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "skip_tests=false" >> $GITHUB_OUTPUT
          fi

      - name: Get changed files
        if: steps.check_skip.outputs.skip_tests == 'false'
        id: changed-files
        uses: tj-actions/changed-files@v46.0.5

      - name: Install/Update Dependencies
        if: steps.check_skip.outputs.skip_tests == 'false'
        run: |
          pip uninstall -y flash-linear-attention
          pip install -U uv
          uv pip install -U pytest setuptools wheel ninja

          # Core logic to install the correct PyTorch version for the specified hardware
          echo "Installing PyTorch version: ${{ inputs.pytorch_version }} for GPU: ${{ inputs.gpu_type }}"

          if [ "${{ inputs.gpu_type }}" = "nvidia" ]; then
            conda install nvidia/label/cuda-12.8.1::cuda-nvcc -y
            if [ "${{ inputs.pytorch_version }}" = "nightly" ]; then
              # Install PyTorch Nightly for NVIDIA
              NIGHTLY_URL="https://download.pytorch.org/whl/nightly/${PYTORCH_CUDA_VERSION}"
              echo "Using nightly index URL: $NIGHTLY_URL"
              uv pip install -U torch --index-url $NIGHTLY_URL
              uv pip install -U packaging psutil ninja
              # If is H100, install causal-conv1d from a specific commit
              if [ "${{ inputs.runner }}" = "nvidia-h100" ]; then
                echo "Installing causal-conv1d for H100"
                uv pip install git+https://github.com/Dao-AILab/causal-conv1d.git@a4b40 --no-build-isolation
              fi
              pip install --no-deps .
            else
              # Install stable PyTorch versions for NVIDIA
              STABLE_URL="https://download.pytorch.org/whl/${PYTORCH_CUDA_VERSION}"
              echo "Using stable index URL: $STABLE_URL"
              uv pip install -U torch~=${{ inputs.pytorch_version }} triton --index-url $STABLE_URL
              pip install .
            fi
            # Install flash-attn separately, as recommended
            echo "Installing flash-attn for NVIDIA"
            uv pip install -U flash-attn --no-cache-dir --no-build-isolation
          elif [ "${{ inputs.gpu_type }}" = "intel" ]; then
            # Install PyTorch for Intel XPU
            XPU_URL="https://download.pytorch.org/whl/xpu"
            echo "Using XPU index URL: $XPU_URL"
            # Note: Intel may not have all torch versions, default is used here.
            uv pip install -U torch~=${{ inputs.pytorch_version }} pytorch-triton-xpu --index-url $XPU_URL
            pip install .
          else
            echo "::error::Unsupported GPU type: ${{ inputs.gpu_type }}"
            exit 1
          fi

      # =================================================================
      # STAGE 2: OPS TESTS
      # =================================================================
      - name: Find dependent test files for Ops
        if: steps.check_skip.outputs.skip_tests == 'false'
        id: find-ops-tests
        run: |
          TEST_FILES=$(TEST_SCOPE=EXCLUDE_MODELS python scripts/find_dependent_tests.py "${{ steps.changed-files.outputs.all_changed_files }}")
          echo "Found ops test files: $TEST_FILES"
          echo "test_files=$TEST_FILES" >> $GITHUB_OUTPUT

      - name: Run pytest on ops test files
        if: steps.find-ops-tests.outputs.test_files && steps.check_skip.outputs.skip_tests == 'false'
        run: |
          TRITON_PRINT_AUTOTUNING=0 SKIP_TEST_CHUNK_VARLEN=1 \
            pytest -s -v ${{ steps.find-ops-tests.outputs.test_files }}

      - name: Run pytest on ops varlen test files
        if: steps.find-ops-tests.outputs.test_files && steps.check_skip.outputs.skip_tests == 'false'
        run: |
          TRITON_PRINT_AUTOTUNING=0 SKIP_TEST_CHUNK_VARLEN=0 \
            pytest -s -v ${{ steps.find-ops-tests.outputs.test_files }} || \
            echo "Varlen tests failed for ops (non-critical)"

      - name: Verify FLA import
        run: |
          python -c "import fla; print('FLA imported successfully')"

  test-models:
    runs-on: ${{ inputs.runner }}
    needs: test-ops
    if: always()
    env:
      FLA_CI_ENV: 1
      PYTORCH_CUDA_VERSION: 'cu128'

    steps:
      # =================================================================
      # STAGE 1: SETUP (Runs only once for the entire job)
      # =================================================================
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Discover Conda Path by Searching Home Directory
        id: find_conda
        shell: bash
        run: |
          set -e
          echo "Searching for Conda installation in home directory ($HOME)..."
          POSSIBLE_NAMES=("miniforge3" "miniconda3" "anaconda3")
          FOUND_PATH=""

          for name in "${POSSIBLE_NAMES[@]}"; do
            CANDIDATE_PATH="$HOME/$name"
            echo "--> Checking for path: ${CANDIDATE_PATH}"
            if [ -d "${CANDIDATE_PATH}" ] && [ -x "${CANDIDATE_PATH}/bin/conda" ]; then
              echo "    Found valid Conda installation: ${CANDIDATE_PATH}"
              FOUND_PATH="${CANDIDATE_PATH}"
              break
            fi
          done

          if [ -n "${FOUND_PATH}" ]; then
            echo "Setting CONDA environment variable to: ${FOUND_PATH}"
            echo "CONDA=${FOUND_PATH}" >> $GITHUB_ENV
          else
            echo "::error::Could not automatically find a Conda installation."
            exit 1
          fi

      - name: Set up Conda from Discovered Path
        uses: conda-incubator/setup-miniconda@v3
        with:
          activate-environment: ""
          auto-update-conda: false
          auto-activate-base: false

      - name: Verify Environment and GPU
        run: |
          conda activate ${{ inputs.conda_env_name }}
          echo "Successfully activated Conda environment: $CONDA_DEFAULT_ENV"

      - name: Check skip keyword in LATEST commit (Push only)
        id: check_skip
        run: |
          if [ "${{ github.event_name }}" = "push" ] && ! [[ "${{ github.ref }}" =~ ^refs/tags/ ]]; then
            COMMIT_MSG=$(jq -r '.head_commit.message' <<< '${{ toJSON(github.event) }}')
            echo "Latest commit message: $COMMIT_MSG"
            if echo "$COMMIT_MSG" | grep -qF "[skip test]"; then
              echo "::notice::Tests skipped by commit message"
              echo "skip_tests=true" >> $GITHUB_OUTPUT
            else
              echo "skip_tests=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "skip_tests=false" >> $GITHUB_OUTPUT
          fi

      - name: Get changed files
        if: steps.check_skip.outputs.skip_tests == 'false'
        id: changed-files
        uses: tj-actions/changed-files@v46.0.5

      # =================================================================
      # STAGE 3: MODELS TESTS (Reuses the same activated environment)
      # =================================================================
      - name: Find dependent test files for Models
        if: steps.check_skip.outputs.skip_tests == 'false'
        id: find-models-tests
        run: |
          TEST_FILES=$(TEST_SCOPE=MODELS_ONLY python scripts/find_dependent_tests.py "${{ steps.changed-files.outputs.all_changed_files }}")
          echo "Found models test files: $TEST_FILES"
          echo "test_files=$TEST_FILES" >> $GITHUB_OUTPUT

      - name: Run pytest on models test files
        if: steps.find-models-tests.outputs.test_files && steps.check_skip.outputs.skip_tests == 'false'
        run: |
          TRITON_PRINT_AUTOTUNING=0 SKIP_TEST_CHUNK_VARLEN=1 \
            pytest -s -v ${{ steps.find-models-tests.outputs.test_files }}

      - name: Run pytest on models varlen test files
        if: steps.find-models-tests.outputs.test_files && steps.check_skip.outputs.skip_tests == 'false'
        run: |
          TRITON_PRINT_AUTOTUNING=0 SKIP_TEST_CHUNK_VARLEN=0 \
            pytest -s -v ${{ steps.find-models-tests.outputs.test_files }} || \
            echo "Varlen tests failed for models (non-critical)"
